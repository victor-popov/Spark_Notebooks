{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "java8_location= '/usr/lib/jvm/java-8-openjdk-amd64' # Set your own\n",
    "os.environ['JAVA_HOME'] = java8_location\n",
    "\n",
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([('a', 1), ('a', 2), ('b', 3), ('c', 4)], numSlices=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b', <pyspark.resultiterable.ResultIterable at 0x7fa151f06940>),\n",
       " ('c', <pyspark.resultiterable.ResultIterable at 0x7fa151f06a20>),\n",
       " ('a', <pyspark.resultiterable.ResultIterable at 0x7fa151f06a90>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.groupByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', <pyspark.resultiterable.ResultIterable at 0x7fa1518f9128>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.groupByKey().collect()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.resultiterable.ResultIterable at 0x7fa151935080>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.groupByKey().collect()[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in pairs.groupByKey().collect()[2][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce or aggregateByKey if make any calculations on elements (if possible) -> speed up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "groupByKey uses reduce under the hood -> data can be migrating between executors -> can be slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = sc.parallelize(['TX', 'TX', 'CA', 'TX', 'CA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TX', 3), ('CA', 2)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states.map(lambda x: (x,1)).reduceByKey(operator.add).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function passed to reduce operator should be commutative and associative. If you struggle to come up with such function, you can use aggregateByKey, which can take two functions, so that you can prepare values in one function and use them in another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three parameters are required for aggregateByKey:\n",
    "\n",
    "    1) Zero value -> value with which second argument starts with\n",
    "    2) Responsible for adding values from RDD to our zero value\n",
    "    3) Combines results from different partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1)\n",
    "zero_value = set() # initializing a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2)\n",
    "def seq_op(x,y): # adding element to a set\n",
    "    x.add(y) # Spark explicitly allows you to modify the first argumet (which otherwise is considered a bad \n",
    "             # programming style. This prevents from reallocating memory for all your collection every time we add\n",
    "             # a value to it)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3)\n",
    "def comb_op(x,y): # can combine any sets\n",
    "    return x.union(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize([0,0,1,2,5,4,5,5,5]).map(lambda x: ['even' if (x % 2 == 0) else 'odd', x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['even', 0],\n",
       " ['even', 0],\n",
       " ['odd', 1],\n",
       " ['even', 2],\n",
       " ['odd', 5],\n",
       " ['even', 4],\n",
       " ['odd', 5],\n",
       " ['odd', 5],\n",
       " ['odd', 5]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('even', {0, 2, 4}), ('odd', {1, 5})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.aggregateByKey(zero_value, seq_op, comb_op).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another useful example might be calculating averages. \n",
    "\n",
    "We initialize with an emply pair, and adding values to the first element (-> sum) and their count to the second element.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([('B', 1), ('a', 2), ['A', 3], ('d', 4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('A', 3), ('B', 1), ('a', 2), ('d', 4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('d', 4), ('a', 2), ('B', 1), ('A', 3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey(ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['A', 3], ('B', 1), ('a', 2), ('d', 4)]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey(numPartitions=1).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('A', 3), ('B', 1)], [('a', 2)], [('d', 4)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey(numPartitions=3).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 2), ('A', 3), ('B', 1), ('d', 4)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.sortByKey(keyfunc=lambda x: x.lower()).collect()\n",
    "# each key was passed through the keyfunc and then sorted. \n",
    "# It doesn't change the keys, but it use modified keys for sorting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 39"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join operates on two pairs or key-value RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sc.parallelize([(1, 'a'), (2, 'a')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sc.parallelize([(2, 'b'), (3, 'b')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ('a', 'b'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.join(b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = sc.parallelize([(2, 'b'), (3, 'b'), (2, 'c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ('a', 'b')), (2, ('a', 'c'))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.join(c).collect()\n",
    "# we get an output for each of the matches -> all possible combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('a', None)), (2, ('a', 'b'))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.leftOuterJoin(b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ('a', 'b')), (3, (None, 'b'))]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.rightOuterJoin(b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, ('a', None)), (2, ('a', 'b')), (3, (None, 'b'))]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.fullOuterJoin(b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whenever we make outer joins we need to ensure that we are handling None values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of the Join operations take an optional second argument that specifies number of partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When making a Join we potentially move a lot of data across the clusters which can slow down execution. \n",
    "\n",
    "Try to see if you can make fewer joins, or whether it is possible to filter down the data prior to join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 40 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CoGroup allows you to combine two RDDs. It differs from join by the way of handling repeated keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sc.parallelize([(1, 'a'), (2, 'a')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sc.parallelize([(2, 'b'), (2, 'c'), (3, 'd')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, ('a', 'b')), (2, ('a', 'c'))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.join(b).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f43f51c9898>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f51c9780>)),\n",
       " (2,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f43f51c97f0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f51c96d8>)),\n",
       " (3,\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f43f51c97b8>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f51c9630>))]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cogroup(b).collect()\n",
    "# this is great for efficiency, but problematic for printing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  [<pyspark.resultiterable.ResultIterable at 0x7f43f4b18668>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f4b184e0>]),\n",
       " (2,\n",
       "  [<pyspark.resultiterable.ResultIterable at 0x7f43f4b18b70>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f4b18a20>]),\n",
       " (3,\n",
       "  [<pyspark.resultiterable.ResultIterable at 0x7f43f4b185c0>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f43f4b18400>])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cogroup(b).mapValues(lambda x: [x[0], x[1]]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, [['a'], []]), (2, [['a'], ['b', 'c']]), (3, [[], ['d']])]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.cogroup(b).mapValues(lambda x: [list(x[0]), list(x[1])]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
