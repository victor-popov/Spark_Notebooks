{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import os\n",
    "java8_location= '/usr/lib/jvm/java-8-openjdk-amd64' # Set your own\n",
    "os.environ['JAVA_HOME'] = java8_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.map(lambda x: x * 10).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 10, 20, 30, 40, 50, 60, 70, 80, 90]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another approach\n",
    "def times_ten(x):\n",
    "    # It shouldn't use variables, state from outside the function\n",
    "    # because when running in parallel those values can change and not\n",
    "    # all the executors will use the same values\n",
    "    return x * 10\n",
    "\n",
    "numbers.map(times_ten).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map has preservePartitioning argument, that can speed up joins\n",
    "\n",
    "mapPartitions is a way for you to operate on a whole partition at once, which is useful if you want \n",
    "to amortize a certain cost across the elements (e.g. you open a database connection \n",
    "and test each of them against the database). \n",
    "\n",
    "If you just want to see each element once and don't care about sharing stuff across them, use map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mapPartitions is a way for you to operate on a whole partition at once, which is useful if you want to amortize a certain cost across the elements (e.g. you open a database connection and test each of them against the database). If you just want to see each element once and don't care about sharing stuff across them, use map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter -> sql WHERE clause"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_even(x):\n",
    "    return (x % 2) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 4, 6, 8]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.filter(is_even).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calling coallecse after filtering can be friuitful: reduces the number of partitions for your data and minimizes network data and reduce overhead time:\n",
    "\n",
    "numbers = numbers.coalesce(numPartitions=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatMap: one -> many; map: one -> one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sc.textFile('Working Files/04/Audio Standardization Sentences.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oak is strong and also gives shade.',\n",
       " 'Cats and dogs each hate the other.',\n",
       " 'The pipe began to rust while new.',\n",
       " \"Open the crate but don't break the glass.\",\n",
       " 'Add the sum to the product of these three.',\n",
       " 'Thieves who rob friends deserve jail.',\n",
       " 'The ripe taste of cheese improves with age.',\n",
       " 'Act on these orders with great speed.',\n",
       " 'The hog crawled under the high fence.',\n",
       " 'Move the vat over the hot fire.']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.flatMap(lambda x: x.split(' ')) # one list for all of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oak',\n",
       " 'is',\n",
       " 'strong',\n",
       " 'and',\n",
       " 'also',\n",
       " 'gives',\n",
       " 'shade.',\n",
       " 'Cats',\n",
       " 'and',\n",
       " 'dogs',\n",
       " 'each',\n",
       " 'hate',\n",
       " 'the',\n",
       " 'other.',\n",
       " 'The',\n",
       " 'pipe',\n",
       " 'began',\n",
       " 'to',\n",
       " 'rust',\n",
       " 'while',\n",
       " 'new.',\n",
       " 'Open',\n",
       " 'the',\n",
       " 'crate',\n",
       " 'but',\n",
       " \"don't\",\n",
       " 'break',\n",
       " 'the',\n",
       " 'glass.',\n",
       " 'Add',\n",
       " 'the',\n",
       " 'sum',\n",
       " 'to',\n",
       " 'the',\n",
       " 'product',\n",
       " 'of',\n",
       " 'these',\n",
       " 'three.',\n",
       " 'Thieves',\n",
       " 'who',\n",
       " 'rob',\n",
       " 'friends',\n",
       " 'deserve',\n",
       " 'jail.',\n",
       " 'The',\n",
       " 'ripe',\n",
       " 'taste',\n",
       " 'of',\n",
       " 'cheese',\n",
       " 'improves',\n",
       " 'with',\n",
       " 'age.',\n",
       " 'Act',\n",
       " 'on',\n",
       " 'these',\n",
       " 'orders',\n",
       " 'with',\n",
       " 'great',\n",
       " 'speed.',\n",
       " 'The',\n",
       " 'hog',\n",
       " 'crawled',\n",
       " 'under',\n",
       " 'the',\n",
       " 'high',\n",
       " 'fence.',\n",
       " 'Move',\n",
       " 'the',\n",
       " 'vat',\n",
       " 'over',\n",
       " 'the',\n",
       " 'hot',\n",
       " 'fire.']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Oak', 'is', 'strong', 'and', 'also', 'gives', 'shade.'],\n",
       " ['Cats', 'and', 'dogs', 'each', 'hate', 'the', 'other.'],\n",
       " ['The', 'pipe', 'began', 'to', 'rust', 'while', 'new.'],\n",
       " ['Open', 'the', 'crate', 'but', \"don't\", 'break', 'the', 'glass.'],\n",
       " ['Add', 'the', 'sum', 'to', 'the', 'product', 'of', 'these', 'three.'],\n",
       " ['Thieves', 'who', 'rob', 'friends', 'deserve', 'jail.'],\n",
       " ['The', 'ripe', 'taste', 'of', 'cheese', 'improves', 'with', 'age.'],\n",
       " ['Act', 'on', 'these', 'orders', 'with', 'great', 'speed.'],\n",
       " ['The', 'hog', 'crawled', 'under', 'the', 'high', 'fence.'],\n",
       " ['Move', 'the', 'vat', 'over', 'the', 'hot', 'fire.']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.map(lambda x: x.split(' ')).collect() # one list for each sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition - chunk of data in RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = sc.textFile('Working Files/04/Audio Standardization Sentences.txt', minPartitions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = text.flatMap(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(iterator):\n",
    "    counts = {}\n",
    "    for w in iterator:\n",
    "        if w in counts:\n",
    "            counts[w] += 1\n",
    "        else:\n",
    "            counts[w] = 1\n",
    "    yield counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The yield statement suspends functionâ€™s execution and sends a value back to caller, but retains enough state to enable function to resume where it is left off. When resumed, the function continues execution immediately after the last yield run. This allows its code to produce a series of values over time, rather them computing them at once and sending them back like a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = words.mapPartitions(count_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Oak': 1,\n",
       "  'is': 1,\n",
       "  'strong': 1,\n",
       "  'and': 2,\n",
       "  'also': 1,\n",
       "  'gives': 1,\n",
       "  'shade.': 1,\n",
       "  'Cats': 1,\n",
       "  'dogs': 1,\n",
       "  'each': 1,\n",
       "  'hate': 1,\n",
       "  'the': 1,\n",
       "  'other.': 1,\n",
       "  'The': 1,\n",
       "  'pipe': 1,\n",
       "  'began': 1,\n",
       "  'to': 1,\n",
       "  'rust': 1,\n",
       "  'while': 1,\n",
       "  'new.': 1},\n",
       " {'Open': 1,\n",
       "  'the': 4,\n",
       "  'crate': 1,\n",
       "  'but': 1,\n",
       "  \"don't\": 1,\n",
       "  'break': 1,\n",
       "  'glass.': 1,\n",
       "  'Add': 1,\n",
       "  'sum': 1,\n",
       "  'to': 1,\n",
       "  'product': 1,\n",
       "  'of': 1,\n",
       "  'these': 1,\n",
       "  'three.': 1},\n",
       " {'Thieves': 1,\n",
       "  'who': 1,\n",
       "  'rob': 1,\n",
       "  'friends': 1,\n",
       "  'deserve': 1,\n",
       "  'jail.': 1,\n",
       "  'The': 1,\n",
       "  'ripe': 1,\n",
       "  'taste': 1,\n",
       "  'of': 1,\n",
       "  'cheese': 1,\n",
       "  'improves': 1,\n",
       "  'with': 1,\n",
       "  'age.': 1},\n",
       " {'Act': 1,\n",
       "  'on': 1,\n",
       "  'these': 1,\n",
       "  'orders': 1,\n",
       "  'with': 1,\n",
       "  'great': 1,\n",
       "  'speed.': 1},\n",
       " {'The': 1,\n",
       "  'hog': 1,\n",
       "  'crawled': 1,\n",
       "  'under': 1,\n",
       "  'the': 3,\n",
       "  'high': 1,\n",
       "  'fence.': 1,\n",
       "  'Move': 1,\n",
       "  'vat': 1,\n",
       "  'over': 1,\n",
       "  'hot': 1,\n",
       "  'fire.': 1}]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mapPartitions allows you to perform an expensive operation \n",
    "#e.g. connecting to database once for each partition, instead of once for each element:\n",
    "def faster_lookup(iterator):\n",
    "    db = make_db_connection()\n",
    "    for id in iterator:\n",
    "        yield db.lookup(id)\n",
    "# this iterates through all of the items of iterator, but creating db connection just once per partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference from mapPartitions is that also provides partition index (besides iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(index, iterator):\n",
    "    db = make_db_connection()\n",
    "    for id in iterator:\n",
    "        yield db.store(id, shard=index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(range(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "979"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(withReplacement=False, fraction=0.1, seed=None).count()\n",
    "# fraction parameter represents the aproximate fraction of the dataset that will be returned. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize(range(5))\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = sc.parallelize(range(4, 10))\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.union(rdd2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([1,1,2,3,4,5])\n",
    "rdd1.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 4, 6]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = sc.parallelize([1,1,4,6])\n",
    "rdd2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1.intersection(rdd2).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce happens under the hood (for duplicate removal) -> can slow down execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 0),\n",
       " ('a', 1),\n",
       " ('a', 2),\n",
       " ('a', 3),\n",
       " ('a', 4),\n",
       " ('a', 5),\n",
       " ('a', 6),\n",
       " ('a', 7),\n",
       " ('a', 8),\n",
       " ('a', 9),\n",
       " ('b', 0),\n",
       " ('b', 1),\n",
       " ('b', 2),\n",
       " ('b', 3),\n",
       " ('b', 4),\n",
       " ('b', 5),\n",
       " ('b', 6),\n",
       " ('b', 7),\n",
       " ('b', 8),\n",
       " ('b', 9)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(['a', 'b']).cartesian(sc.parallelize(range(10)))\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b',\n",
       " 'b']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first = rdd.map(lambda x: x[0])\n",
    "first.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'a']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first.distinct().collect()\n",
    "# disstinct has optional argument \"numPartitions\", the larger is it, the greater the parallelism will be\n",
    "# distinct is a \"reduce-type\" transformation -> can be slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (0, 6),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (3, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (4, 0),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (4, 5),\n",
       " (4, 6)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cartesian product (all possible pairs) in Python:\n",
    "ice_creams = range(5)\n",
    "cookies = range(7)\n",
    "[(a,b) for a in ice_creams for b in cookies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cartesian product (all possible pairs) in Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ice_creams = sc.parallelize(range(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cookies = sc.parallelize(range(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = ice_creams.cartesian(cookies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1),\n",
       " (0, 2),\n",
       " (0, 3),\n",
       " (0, 4),\n",
       " (0, 5),\n",
       " (0, 6),\n",
       " (1, 0),\n",
       " (1, 1),\n",
       " (1, 2),\n",
       " (1, 3),\n",
       " (1, 4),\n",
       " (1, 5),\n",
       " (1, 6),\n",
       " (2, 0),\n",
       " (2, 1),\n",
       " (2, 2),\n",
       " (2, 3),\n",
       " (2, 4),\n",
       " (2, 5),\n",
       " (2, 6),\n",
       " (3, 0),\n",
       " (4, 0),\n",
       " (3, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (4, 2),\n",
       " (3, 3),\n",
       " (3, 4),\n",
       " (4, 3),\n",
       " (4, 4),\n",
       " (3, 5),\n",
       " (3, 6),\n",
       " (4, 5),\n",
       " (4, 6)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinations.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For large data it makes sense to perform cartesian product on data subsets. Consider using join operations or broadcast variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '10']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# selecting records that contain 1\n",
    "numbers.pipe('grep 1').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe passes all of the data as strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipe can be used with any tool, program, language, that can take values from stdIN and write to stdOUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " input and output happens at the partition level -> no need to worry about CLI overhead as it will be started just once per partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b,b', 'c,c,c', 'a']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize(['b,b', 'c,c,c', 'a'])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B,B', 'C,C,C', 'A']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pipe to capitalize everything\n",
    "rdd.pipe(\"tr '[a-z]' '[A-Z]'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pipe as a filter\n",
    "rdd.pipe('grep a').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['b', 'b', 'c', 'c', 'c', 'a']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pipe as a flatmap: one line in stdIN, multiple lines in stdOUT\n",
    "rdd.pipe(\"tr -s ',' '[\\n*]'\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduces number of partitions in an efficeint way by combining partitions that are on the same executors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.parallelize(range(10000), numSlices=100)\n",
    "# rdd with a 100 partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd2 = rdd.coalesce(10)\n",
    "# reduced # of partitions from 100 to 10 with minimum of data movement between executors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of partitions is an upper bound for parallelism: we can't have 5 processors working on 3 partitions\n",
    "\n",
    "Spark recommends 2-4 partitions per cpu in the cluster\n",
    "\n",
    "Too many partitions -> every time we start a comutation, many tast overhead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition allows you to set the resulting number of partitions. Similar to coalesce, but we can also grow number of partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = sc.parallelize(range(1000), numSlices=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[82] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbers.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sending data from its current location to a new host executor which can be a lot of network traffic. For reducing number of partitions use coalesce method as it often requires less network traffic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repartition and sorting afterwards is less efficient than RepartitionAndSortWithinPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting happens for a key-value pairs by keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = sc.parallelize([[1,2], [1,1], [2,3], [3,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 3)], [(1, 2), (1, 1), (3, 3)]]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.repartitionAndSortWithinPartitions(2).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glom takes all of the elements within a partition and puts them to a list and returns RDD of those lists.\n",
    "\n",
    "2 lists above represent 2 partitions we requested to make. Within those partitions pairs are sorted based on keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(2, 3), (3, 3)], [(1, 2), (1, 1)]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs.repartitionAndSortWithinPartitions(2, partitionFunc=lambda x: x == 1).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partitionFunc=lambda x: x == 1 -> for each key that comes to partition, does it equal to 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "additional params:\n",
    "    \n",
    "    -ascending\n",
    "    \n",
    "    -keyfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
